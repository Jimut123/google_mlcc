{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week2_task.ipynb","version":"0.3.2","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"vJ-NzZ0BJcTg","colab_type":"toc"},"cell_type":"markdown","source":[">[Introduction](#scrollTo=1vNpobIiIcYq)\n","\n",">[Loading the data](#scrollTo=2lCpzgnrIgxv)\n","\n",">>[Task 1: Randomize the data](#scrollTo=MqeZPcDyIl6P)\n","\n",">[Defining the functions](#scrollTo=u49aNgQLIr36)\n","\n",">>[Task 2: Complete the functions](#scrollTo=vv0kJy_DIwYi)\n","\n",">[Creating training and test sets](#scrollTo=MQ6GkWVHI0-O)\n","\n",">>[Task 3: Complete the codes](#scrollTo=uPhdEtlfI5fi)\n","\n",">[Defining the input functions](#scrollTo=voToN4G2JBaa)\n","\n",">[Defining the train_model functions](#scrollTo=EM44SV9nJFcf)\n","\n",">>[Task 4: Complete the code](#scrollTo=dp1Bmsu_JJGn)\n","\n",">[Traing and predict](#scrollTo=nA2rvcPYJQ33)\n","\n",">>[Task 5: Get a loss less than 8.7](#scrollTo=DWJVDOiJJUmB)\n","\n"]},{"metadata":{"id":"1vNpobIiIcYq","colab_type":"text"},"cell_type":"markdown","source":["# Introduction"]},{"metadata":{"id":"TSPGIUSoyL88","colab_type":"text"},"cell_type":"markdown","source":["In this task, we'll be using the Boston housing dataset that comes prebuilt with sklearn. The first part is usual improting routine."]},{"metadata":{"id":"swSkIrpBoI8z","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import print_function\n","\n","import math\n","\n","from IPython import display\n","from matplotlib import cm\n","from matplotlib import gridspec\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from sklearn import metrics\n","import tensorflow as tf\n","from tensorflow.python.data import Dataset\n","\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","pd.options.display.max_rows = 10\n","pd.options.display.float_format = '{:.1f}'.format"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2lCpzgnrIgxv","colab_type":"text"},"cell_type":"markdown","source":["# Loading the data"]},{"metadata":{"id":"PG-ZXW1byX3p","colab_type":"text"},"cell_type":"markdown","source":["Here we load the dataset. **It is important you read the description and know which column denotes what since the names are not meaningful by themselves**"]},{"metadata":{"id":"Isqbk1nJwnJm","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.datasets import load_boston\n","\n","boston = load_boston()\n","print(boston.DESCR)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4Dd9jhz_heQx","colab_type":"text"},"cell_type":"markdown","source":["As you can see, the boston dataset has a different format than what we have been using, so we will convert it to a Pandas dataframe."]},{"metadata":{"id":"ie7pZQM0pD4x","colab_type":"code","colab":{}},"cell_type":"code","source":["boston_housing_dataframe = pd.DataFrame(boston.data)\n","boston_housing_dataframe.columns = boston.feature_names\n","boston_housing_dataframe['PRICE'] = boston.target"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tDgSmRZ53VGt","colab_type":"text"},"cell_type":"markdown","source":["Check the data"]},{"metadata":{"id":"e9RTfeIsp1LN","colab_type":"code","colab":{}},"cell_type":"code","source":["boston_housing_dataframe.describe()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MqeZPcDyIl6P","colab_type":"text"},"cell_type":"markdown","source":["## Task 1: Randomize the data"]},{"metadata":{"id":"Htyl56yg3XI2","colab_type":"text"},"cell_type":"markdown","source":["Your first task is to write the code to randomize the data."]},{"metadata":{"id":"Dk9ueJZSp2ZL","colab_type":"code","colab":{}},"cell_type":"code","source":["# RANDOMIZE THE DATA"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u49aNgQLIr36","colab_type":"text"},"cell_type":"markdown","source":["# Defining the functions"]},{"metadata":{"id":"vv0kJy_DIwYi","colab_type":"text"},"cell_type":"markdown","source":["## Task 2: Complete the functions"]},{"metadata":{"id":"MNK3lw9z3cmU","colab_type":"text"},"cell_type":"markdown","source":["For our target, we'll be using **\"PRICE\"** column and for the input features, we'll be using all the remaining columns.\n","\n","Your tasks are - \n","\n","1. Complete the **selected_features** list to include the rest of the input features.\n","2. complete the **processed_features** function to construct a dataframe and extract the PRICE column"]},{"metadata":{"id":"1SV4WF0xqDEv","colab_type":"code","colab":{}},"cell_type":"code","source":["def preprocess_features(boston_housing_dataframe):\n","\n","  selected_features = boston_housing_dataframe[\n","    [\"CRIM\",\n","     \"ZN\",\n","     \"INDUS\",\n","     \"CHAS\",\n","     \"NOX\",\n","     # WRITE THE REST OF THE FEATURE COLUMNS\n","    ]]\n","  processed_features = selected_features.copy()\n","  return processed_features\n","\n","def preprocess_targets(boston_housing_dataframe):\n","  output_targets = # CONSTRUCT A DATAFRAME HERE WHICH HOLDS THE PRICE COLUMN FROM THE ACTUAL DATAFRAME\n","  return output_targets"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MQ6GkWVHI0-O","colab_type":"text"},"cell_type":"markdown","source":["# Creating training and test sets"]},{"metadata":{"id":"uPhdEtlfI5fi","colab_type":"text"},"cell_type":"markdown","source":["## Task 3: Complete the codes"]},{"metadata":{"id":"aA7VKrTd4DZ5","colab_type":"text"},"cell_type":"markdown","source":["There are only 506 datapoints. We'll use the first 380 examples (~75%) for training data and last 126 for validation.\n","\n","Your task is to create the appropriate datasets."]},{"metadata":{"id":"52wVvEKEruaj","colab_type":"code","colab":{}},"cell_type":"code","source":["training_examples = # GET THE FIRST 380 FEATURE VALUES AND PREPROCESS THEM\n","training_examples.describe()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gjv4xV0hr8as","colab_type":"code","colab":{}},"cell_type":"code","source":["training_targets = # GET THE LAST 126 PRICE VALUES AND PREPROCESS IT\n","training_targets.describe()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h-hFMW6rsBO_","colab_type":"code","colab":{}},"cell_type":"code","source":["validation_examples = # GET THE LAST 126 FEATURE VALUES AND PREPROCESS THEM\n","validation_examples.describe()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CKIyAZORsJDR","colab_type":"code","colab":{}},"cell_type":"code","source":["validation_targets = # GET THE LAST 126 PRICE VALUES AND PREPROCESS IT\n","validation_targets.describe()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"voToN4G2JBaa","colab_type":"text"},"cell_type":"markdown","source":["# Defining the input functions"]},{"metadata":{"id":"D4W5zrfU4XBW","colab_type":"text"},"cell_type":"markdown","source":["The input function and construct_feature_column function is defined as before."]},{"metadata":{"id":"h0qPuD13sV3q","colab_type":"code","colab":{}},"cell_type":"code","source":["def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n","   \n","    \n","    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n"," \n","    ds = Dataset.from_tensor_slices((features,targets)) \n","    ds = ds.batch(batch_size).repeat(num_epochs)\n","\n","    if shuffle:\n","      ds = ds.shuffle(10000)\n","\n","    features, labels = ds.make_one_shot_iterator().get_next()\n","    return features, labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"shdlJZuTsYUo","colab_type":"code","colab":{}},"cell_type":"code","source":["def construct_feature_columns(input_features):\n","\n","  return set([tf.feature_column.numeric_column(my_feature)\n","              for my_feature in input_features])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EM44SV9nJFcf","colab_type":"text"},"cell_type":"markdown","source":["# Defining the train_model functions"]},{"metadata":{"id":"dp1Bmsu_JJGn","colab_type":"text"},"cell_type":"markdown","source":["## Task 4: Complete the code"]},{"metadata":{"id":"HIr3K2Pw58ol","colab_type":"text"},"cell_type":"markdown","source":["The train model function is all the same. Your task is to - \n","\n","1. Put the num_epochs and shuffle parameters accordingly (they're all prediction functions, so they'll have a certain value)\n","2. Predict on the validation set and convert into numpy array"]},{"metadata":{"id":"XKD8JbxvsgJi","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_model(\n","    learning_rate,\n","    steps,\n","    batch_size,\n","    training_examples,\n","    training_targets,\n","    validation_examples,\n","    validation_targets):\n","\n","  periods = 10\n","  steps_per_period = steps / periods\n","\n","  my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n","  my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n","  linear_regressor = tf.estimator.LinearRegressor(\n","      feature_columns=construct_feature_columns(training_examples),\n","      optimizer=my_optimizer\n","  )\n","  \n","  training_input_fn = lambda: my_input_fn(\n","      training_examples, \n","      training_targets[\"PRICE\"], \n","      batch_size=batch_size)\n","  predict_training_input_fn = lambda: my_input_fn(\n","      training_examples, \n","      training_targets[\"PRICE\"], \n","      # PUT num_epochs AND shuffle VALUES ACCORDINGLY\n","  )\n","  predict_validation_input_fn = lambda: my_input_fn(\n","      validation_examples, validation_targets[\"PRICE\"], \n","      # PUT num_epochs AND shuffle VALUES ACCORDINGLY\n","  )\n","\n","  print(\"Training model...\")\n","  print(\"RMSE (on training data):\")\n","  training_rmse = []\n","  validation_rmse = []\n","  for period in range (0, periods):\n","    linear_regressor.train(\n","        input_fn=training_input_fn,\n","        steps=steps_per_period,\n","    )\n"," \n","    training_predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n","    training_predictions = np.array([item['predictions'][0] for item in training_predictions])\n","    \n","    validation_predictions = # MAKE THE PREDICTION ON VALIDATION SET\n","    validation_predictions = # CONVERT INTO A NUMPY ARRAY\n","    \n","    training_root_mean_squared_error = math.sqrt(\n","        metrics.mean_squared_error(training_predictions, training_targets))\n","    validation_root_mean_squared_error = math.sqrt(\n","        metrics.mean_squared_error(validation_predictions, validation_targets))\n","    print(\"  period %02d : %0.2f\" % (period, training_root_mean_squared_error))\n","    training_rmse.append(training_root_mean_squared_error)\n","    validation_rmse.append(validation_root_mean_squared_error)\n","  print(\"Model training finished.\")\n","\n","  plt.ylabel(\"RMSE\")\n","  plt.xlabel(\"Periods\")\n","  plt.title(\"Root Mean Squared Error vs. Periods\")\n","  plt.tight_layout()\n","  plt.plot(training_rmse, label=\"training\")\n","  plt.plot(validation_rmse, label=\"validation\")\n","  plt.legend()\n","\n","  return linear_regressor"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nA2rvcPYJQ33","colab_type":"text"},"cell_type":"markdown","source":["# Traing and predict"]},{"metadata":{"id":"DWJVDOiJJUmB","colab_type":"text"},"cell_type":"markdown","source":["## Task 5: Get a loss less than 8.7"]},{"metadata":{"id":"2-qwLEgV6U23","colab_type":"text"},"cell_type":"markdown","source":["Finally, find a proper learning rate, steps and batch size to get a loss less than 8.7"]},{"metadata":{"id":"LY1RFwaKsr8X","colab_type":"code","colab":{}},"cell_type":"code","source":["linear_regressor = train_model(\n","    learning_rate= # PUT A VALUE,\n","    steps=# PUT A VALUE,\n","    batch_size=# PUT A VALUE,\n","    training_examples=training_examples,\n","    training_targets=training_targets,\n","    validation_examples=validation_examples,\n","    validation_targets=validation_targets)"],"execution_count":0,"outputs":[]}]}